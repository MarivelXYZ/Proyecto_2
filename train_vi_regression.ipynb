{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nos aseguramos de usar solamente ciertas GPUs\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import rasterio\n",
    "import sys\n",
    "# import random  \n",
    "from random import sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read SSI file data\n",
    "#work with occupancy\n",
    "df = pd.read_csv('/data/gee/SSI nacional/X_SSI_pp.csv')\n",
    "ssi = df['pro_ocup_c']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matlab equivalent to find\n",
    "def indices(a, func):\n",
    "    return [i for (i, val) in enumerate(a) if func(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform ssi to a list\n",
    "vi = ssi.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit value and normalize resulting items\n",
    "indx_tau = indices(vi, lambda vi: vi  > tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(indx_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_array = np.array(vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_array[indx_tau] = tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_array = vi_array/tau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx_items = indices(vi, lambda vi: (vi>0) & (vi <1)) #limit values for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_selected = vi_array[indx_items] #vulnerability elements of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of locations = 630203\n"
     ]
    }
   ],
   "source": [
    "num_imgs = len(indx_items)\n",
    "print('number of locations = %d' % num_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lon = df['X_CENT']\n",
    "lat = df['Y_CENT']\n",
    "lon_selected = lon[indx_items]\n",
    "lat_selected = lat[indx_items] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read image folders file\n",
    "df = pd.read_csv('DataSetGeomedianaV2_X_SSI_pp.csv')\n",
    "folder = df['folder']\n",
    "img_ini = df['img_ini']\n",
    "img_end = df['img_end']\n",
    "\n",
    "#image path\n",
    "path = '/data/gee/DataSetGeomedianaV2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain image filename given the region index\n",
    "def image_filename(index):\n",
    "    indf = 0\n",
    "    for i in np.arange(0,32):\n",
    "        if (index>=img_ini[i] and index<=img_end[i]):\n",
    "            indf = i\n",
    "    img_fn = path + folder[indf] + '/_' + f'{index:07}' + '.tif'\n",
    "    return img_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifying ssi with a threshold\n",
    "n = len(vi_selected)\n",
    "#th_ssi = 0.2\n",
    "\n",
    "#ind = np.arange(0,num_imgs)\n",
    "\n",
    "#pov = np.zeros(num_imgs).astype(int)\n",
    "#pov[ssi>=th_ssi] = 1\n",
    "\n",
    "#num_pos = np.sum(ssi>=th_ssi)\n",
    "#num_neg = np.sum(ssi<th_ssi)\n",
    "\n",
    "#print(num_pos, num_neg)\n",
    "#print(num_pos/num_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove negative samples\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "\n",
    "#ind_pos = ind[pov==1]\n",
    "#ind_neg = ind[pov==0]\n",
    "#ind_neg = random.sample(list(ind_neg), num_pos)\n",
    "\n",
    "#ind_sel = np.concatenate((ind_pos, ind_neg))\n",
    "#num_sel = len(ind_sel)\n",
    "\n",
    "#print(num_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315102 157551 157550\n"
     ]
    }
   ],
   "source": [
    "#split indices for training, validation and testing\n",
    "num_train = np.round(0.5*num_imgs).astype(int)\n",
    "num_val = np.round(0.25*num_imgs).astype(int)\n",
    "num_test = num_imgs - num_train - num_val\n",
    "\n",
    "random.shuffle(indx_items)\n",
    "ind_train = indx_items[0:num_train]\n",
    "ind_val = indx_items[num_train:num_train+num_val]\n",
    "ind_test = indx_items[num_train+num_val:num_imgs]\n",
    "\n",
    "print(len(ind_train), len(ind_val), len(ind_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/gee/DataSetGeomedianaV2/05_Coahuila/_0161400.tif\n",
      "(6, 20, 20)\n",
      "2290.5616666666665\n"
     ]
    }
   ],
   "source": [
    "#test one image\n",
    "indx = 161400\n",
    "#channels = [1,2,3]\n",
    "channels = [1,2,3,4,5,6]\n",
    "#channels = [4,5,6]\n",
    "img_fn = image_filename(indx)\n",
    "image = rasterio.open(img_fn)\n",
    "img = image.read(channels)\n",
    "image.close()\n",
    "\n",
    "print(img_fn)\n",
    "print(np.shape(img))\n",
    "print(np.mean(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315083, 20, 20, 6)\n"
     ]
    }
   ],
   "source": [
    "#image size\n",
    "image_width = 20 \n",
    "image_height = 20\n",
    "#rescale intensity values\n",
    "rescale = 1.0/1.0e4\n",
    "\n",
    "#load training images\n",
    "images_train = []\n",
    "ind_train_valid = []\n",
    "for indx in ind_train: #for all the training images\n",
    "    img_fn = image_filename(indx) #get the filename\n",
    "    if (os.path.isfile(img_fn)):\n",
    "        image = rasterio.open(img_fn) #open the image\n",
    "        img = image.read(channels) #read the image\n",
    "        image.close() #close the image file\n",
    "        if (np.isnan(np.mean(img))==False):\n",
    "            sz = np.shape(img) #find out the size of the image\n",
    "            imr = np.zeros((sz[1],sz[2],sz[0])) #init an tensor with zeros\n",
    "            for ch in np.arange(0,sz[0]): #copy the image bands\n",
    "                imr[:,:,ch] = img[ch,:,:]\n",
    "            small_array = cv2.resize(imr, (image_width, image_height), cv2.INTER_LINEAR) #resize the image, why?\n",
    "            images_train.append(small_array*rescale) #add it to the output tensor\n",
    "            ind_train_valid.append(indx) #add the number of image to the index list\n",
    "\n",
    "print(np.shape(images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157544, 20, 20, 6)\n"
     ]
    }
   ],
   "source": [
    "#load validation images\n",
    "images_val = [] #init validation tensor\n",
    "ind_val_valid = [] #init the array containing the number of images\n",
    "for indx in ind_val:\n",
    "    img_fn = image_filename(indx)\n",
    "    if (os.path.isfile(img_fn)):\n",
    "        image = rasterio.open(img_fn)\n",
    "        img = image.read(channels)\n",
    "        image.close()\n",
    "        if (np.isnan(np.mean(img))==False):\n",
    "            sz = np.shape(img)\n",
    "            imr = np.zeros((sz[1],sz[2],sz[0]))\n",
    "            for ch in np.arange(0,sz[0]):\n",
    "                imr[:,:,ch] = img[ch,:,:]\n",
    "            small_array = cv2.resize(imr, (image_width, image_height), cv2.INTER_LINEAR)\n",
    "            images_val.append(small_array*rescale)\n",
    "            ind_val_valid.append(indx)\n",
    "\n",
    "print(np.shape(images_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157540, 20, 20, 6)\n"
     ]
    }
   ],
   "source": [
    "#load test images\n",
    "images_test = []\n",
    "ind_test_valid = []\n",
    "for indx in ind_test:\n",
    "    img_fn = image_filename(indx)\n",
    "    if (os.path.isfile(img_fn)):\n",
    "        image = rasterio.open(img_fn)\n",
    "        img = image.read(channels)\n",
    "        image.close()\n",
    "        if (np.isnan(np.mean(img))==False):\n",
    "            sz = np.shape(img)\n",
    "            imr = np.zeros((sz[1],sz[2],sz[0]))\n",
    "            for ch in np.arange(0,sz[0]):\n",
    "                imr[:,:,ch] = img[ch,:,:]\n",
    "            small_array = cv2.resize(imr, (image_width, image_height), cv2.INTER_LINEAR)\n",
    "            images_test.append(small_array*rescale)\n",
    "            ind_test_valid.append(indx)\n",
    "\n",
    "print(np.shape(images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315083, 20, 20, 6)\n",
      "(157544, 20, 20, 6)\n",
      "(157540, 20, 20, 6)\n"
     ]
    }
   ],
   "source": [
    "#input for training the model\n",
    "x_train = np.array(images_train)\n",
    "x_val = np.array(images_val)\n",
    "x_test = np.array(images_test)\n",
    "\n",
    "y_train = vi_array[ind_train_valid]\n",
    "y_val = vi_array[ind_val_valid]\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_val))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sz = np.shape(x_train)\n",
    "\n",
    "#Instantiate an empty model\n",
    "model = Sequential()\n",
    "# C1 Convolutional Layer\n",
    "model.add(layers.Conv2D(6, kernel_size=(5,5), strides=(1,1),\n",
    "  activation='tanh', input_shape=(image_width,image_height,sz[3]),\n",
    "  padding='same'))\n",
    "# S2 Pooling Layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2),\n",
    "  strides=(1, 1), padding='valid'))\n",
    "# C3 Convolutional Layer\n",
    "model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1),\n",
    "  activation='tanh', padding='valid'))\n",
    "# S4 Pooling Layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2),\n",
    "  strides=(2, 2), padding='valid'))\n",
    "# C5 Fully Connected Convolutional Layer\n",
    "model.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1),\n",
    "  activation='tanh', padding='valid'))\n",
    "# Flatten the CNN output so that we can connect it with fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "# FC6 Fully Connected Layer\n",
    "model.add(layers.Dense(84, activation='tanh'))\n",
    "# Output Layer with softmax activation\n",
    "#model.add(layers.Dense(2, activation='softmax'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "learning_rate = 1e-6\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "#model.compile(loss=losses.binary_crossentropy, optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2462/2461 [==============================] - 16s 6ms/step - loss: 0.0020 - mae: 0.0368 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0368 - val_mse: 0.0020\n",
      "Epoch 2/50\n",
      "2462/2461 [==============================] - 15s 6ms/step - loss: 0.0020 - mae: 0.0368 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0368 - val_mse: 0.0020\n",
      "Epoch 3/50\n",
      "2462/2461 [==============================] - 16s 6ms/step - loss: 0.0020 - mae: 0.0368 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0368 - val_mse: 0.0020\n",
      "Epoch 4/50\n",
      "2462/2461 [==============================] - 16s 6ms/step - loss: 0.0020 - mae: 0.0368 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0367 - val_mse: 0.0020\n",
      "Epoch 5/50\n",
      "2462/2461 [==============================] - 16s 6ms/step - loss: 0.0020 - mae: 0.0368 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0367 - val_mse: 0.0020\n",
      "Epoch 6/50\n",
      "2462/2461 [==============================] - 16s 6ms/step - loss: 0.0020 - mae: 0.0368 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0367 - val_mse: 0.0020\n",
      "Epoch 7/50\n",
      "2462/2461 [==============================] - 16s 6ms/step - loss: 0.0020 - mae: 0.0368 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0367 - val_mse: 0.0020\n",
      "Epoch 8/50\n",
      "2462/2461 [==============================] - 16s 6ms/step - loss: 0.0020 - mae: 0.0367 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0367 - val_mse: 0.0020\n",
      "Epoch 9/50\n",
      "2462/2461 [==============================] - 16s 6ms/step - loss: 0.0020 - mae: 0.0367 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0367 - val_mse: 0.0020\n",
      "Epoch 10/50\n",
      "2462/2461 [==============================] - 16s 6ms/step - loss: 0.0020 - mae: 0.0367 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0367 - val_mse: 0.0020\n",
      "Epoch 11/50\n",
      "2380/2461 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0367 - mse: 0.0020"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "batch_size = 128\n",
    "step_size_train = len(x_train) / batch_size\n",
    "step_size_val = len(x_val) / batch_size\n",
    "epochs = 50\n",
    "initial_epoch = 0\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train,\n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    validation_steps=step_size_val,\n",
    "                    epochs=epochs,\n",
    "                    initial_epoch = initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,0.002067,0.002054\n",
      "2,0.002047,0.002049\n",
      "3,0.002043,0.002045\n"
     ]
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "for k in np.arange(initial_epoch,epochs):\n",
    "    print('%d,%0.6f,%0.6f' % (k+1, loss[k], val_loss[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for test images\n",
    "vi_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_real = vi_array[ind_test_valid]\n",
    "vi_pred = np.array(vi_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04511362917481761\n",
      "0.04814096416215141\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rms = mean_squared_error(vi_real, vi_pred, squared=False)\n",
    "print(rms)\n",
    "print(vi_real.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
